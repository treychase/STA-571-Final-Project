---
title: "STA 571 Final Project - Enhanced with Streak Features"
author: "Trey Chase, Tully Cannon"
format:
  pdf:
    toc: true
    number-sections: true
execute:
  echo: true
  warning: false
  message: false
---

# Setup

```{r setup}
library(readr)
library(lme4)  # Load before tidyverse to prevent MASS::select from masking dplyr::select
library(tidyverse)
library(ggplot2)
library(gridExtra)
library(depmixS4)
library(xgboost)
library(nnet)
library(caret)
library(knitr)
library(kableExtra)
library(pROC)
library(zoo)

set.seed(571)
```

# Data Loading

```{r data-loading}
file_path = "~/Downloads/STA 571 Final Project/NBA_2024_Shots.csv"
shots_df = read_csv(file_path, show_col_types = FALSE)
```

# Exploratory Data Analysis

```{r data-prep}
shots_df = shots_df %>%
  mutate(
    SHOT_MADE_NUM = as.integer(SHOT_MADE),
    SHOT_TYPE_NUM = ifelse(SHOT_TYPE == "2PT Field Goal", 2, 3),
    PERIOD = QUARTER,
    TIME_REMAINING = MINS_LEFT * 60 + SECS_LEFT,
    DISTANCE_SQUARED = SHOT_DISTANCE^2
  ) %>%
  filter(!is.na(SHOT_MADE))
```

## Overall Shot Statistics

```{r overall-stats}
shots_df %>%
  summarise(
    n_shots = n(),
    make_rate = mean(SHOT_MADE),
    avg_distance = mean(SHOT_DISTANCE),
    sd_distance = sd(SHOT_DISTANCE)
  ) %>%
  kable(digits = 3, caption = "Overall Shot Statistics")
```

## Shot Statistics by Type

```{r stats-by-type}
shots_df %>%
  group_by(SHOT_TYPE) %>%
  summarise(
    n = n(),
    make_rate = mean(SHOT_MADE),
    .groups = "drop"
  ) %>%
  kable(digits = 3, caption = "Shot Statistics by Type")
```

## Visualizations

```{r viz-plots, fig.width=10, fig.height=8}
p1 = ggplot(shots_df, aes(x = SHOT_DISTANCE, fill = SHOT_MADE)) +
  geom_histogram(bins = 50, position = "identity", alpha = 0.6) +
  labs(x = "Shot Distance (ft)", y = "Count") +
  theme_minimal()

p2 = shots_df %>%
  group_by(SHOT_DISTANCE) %>%
  summarise(make_rate = mean(SHOT_MADE), n = n(), .groups = "drop") %>%
  filter(n >= 100) %>%
  ggplot(aes(x = SHOT_DISTANCE, y = make_rate)) +
  geom_point(alpha = 0.5) +
  geom_smooth(se = FALSE, method = "loess", formula = y ~ x) +
  labs(x = "Shot Distance (ft)", y = "Make Rate") +
  theme_minimal()

p3 = ggplot(shots_df, aes(x = LOC_X, y = LOC_Y, color = SHOT_MADE)) +
  geom_point(alpha = 0.1, size = 0.5) +
  labs(x = "Court X", y = "Court Y") +
  theme_minimal()

p4 = shots_df %>%
  group_by(QUARTER) %>%
  summarise(make_rate = mean(SHOT_MADE), .groups = "drop") %>%
  ggplot(aes(x = QUARTER, y = make_rate)) +
  geom_line() +
  geom_point() +
  labs(x = "Quarter", y = "Make Rate") +
  theme_minimal()

grid.arrange(p1, p2, p3, p4, ncol = 2)
```

## Top Teams by Make Rate

```{r team-stats}
team_stats = shots_df %>%
  group_by(TEAM_NAME) %>%
  summarise(
    n_shots = n(),
    make_rate = mean(SHOT_MADE),
    avg_distance = mean(SHOT_DISTANCE),
    .groups = "drop"
  ) %>%
  arrange(desc(make_rate))

head(team_stats, 10) %>%
  kable(digits = 3, caption = "Top 10 Teams by Make Rate")
```

# Enhanced Data Preparation with Streak Features

```{r streak-features}
# Create comprehensive streak features at team level
shots_df_enhanced = shots_df %>%
  arrange(TEAM_NAME, GAME_ID, QUARTER, desc(MINS_LEFT), desc(SECS_LEFT)) %>%
  group_by(TEAM_NAME) %>%
  mutate(
    # Lagged made shots
    lag1_made = lag(SHOT_MADE_NUM, 1, default = 0),
    lag2_made = lag(SHOT_MADE_NUM, 2, default = 0),
    lag3_made = lag(SHOT_MADE_NUM, 3, default = 0),
    lag4_made = lag(SHOT_MADE_NUM, 4, default = 0),
    lag5_made = lag(SHOT_MADE_NUM, 5, default = 0),
    
    # Recent makes (last N shots)
    recent_makes_3 = lag1_made + lag2_made + lag3_made,
    recent_makes_5 = lag1_made + lag2_made + lag3_made + lag4_made + lag5_made,
    
    # Current streak (consecutive makes)
    streak = {
      s = rep(0, n())
      for(i in 2:n()) {
        if(SHOT_MADE_NUM[i-1] == 1) {
          s[i] = s[i-1] + 1
        }
      }
      s
    },
    
    # Rolling statistics
    rolling_makes_10 = rollsumr(lag(SHOT_MADE_NUM, default = 0),
                                k = 10, fill = 0, align = "right"),
    rolling_rate_10 = rolling_makes_10 / pmin(row_number() - 1, 10)
  ) %>%
  ungroup()
```

## Relationship Between Streaks and Make Rate

```{r streak-analysis}
# Examine relationship between streaks and make rate
shots_df_enhanced %>%
  filter(recent_makes_3 >= 0) %>%
  group_by(recent_makes_3) %>%
  summarise(
    n = n(),
    make_rate = mean(SHOT_MADE),
    .groups = "drop"
  ) %>%
  kable(digits = 3, caption = "Make Rate by Recent Makes (Last 3 Shots)")
```

```{r streak-current}
# Streak analysis
shots_df_enhanced %>%
  filter(streak <= 5) %>%
  group_by(streak) %>%
  summarise(
    n = n(),
    make_rate = mean(SHOT_MADE),
    .groups = "drop"
  ) %>%
  kable(digits = 3, caption = "Make Rate by Current Streak Length")
```

# Model 1: Hidden Markov Model with Streak Covariate

```{r hmm-prep}
team_data = shots_df_enhanced %>%
  filter(TEAM_NAME == team_stats$TEAM_NAME[1]) %>%
  arrange(GAME_ID, QUARTER, desc(MINS_LEFT), desc(SECS_LEFT)) %>%
  mutate(shot_num = row_number()) %>%
  filter(!is.na(rolling_rate_10))  # Remove rows without enough history
```

## HMM Model Specification

The Hidden Markov Model models shot outcomes with hidden states:

$$Y_t|S_t = k, X_t \sim \text{Bernoulli}(\pi_{k,t})$$
$$\text{logit}(\pi_{k,t}) = \beta_{k,0} + \beta_{k,1} \cdot \text{RecentMakes}_t$$
$$S_t|S_{t-1} = j \sim \text{Categorical}(\Gamma_j)$$
$$\Gamma_{jk} = \Pr(S_t = k|S_{t-1} = j)$$

```{r hmm-model}
set.seed(571)

# Create model with streak covariate
hmm_model = depmix(
  response = SHOT_MADE_NUM ~ recent_makes_3,
  data = team_data,
  nstates = 2,
  family = binomial("logit")  # Use logit link
)

# Set reasonable starting values
hmm_model = setpars(hmm_model,
                    value = c(0.5, 0.5,  # initial state probs
                             0.9, 0.1, 0.1, 0.9,  # transition matrix
                             0, 0.3,  # State 1: intercept, slope
                             0.5, 0.5))  # State 2: intercept, slope

hmm_fit = fit(hmm_model,
              verbose = FALSE,
              emcontrol = em.control(maxit = 1000, tol = 1e-8))
```

## HMM Results

```{r hmm-results}
# Check convergence
cat("Log-Likelihood:", logLik(hmm_fit), "\n\n")

cat("AIC:", AIC(hmm_fit), "\n\n")

cat("BIC:", BIC(hmm_fit), "\n\n")

hmm_summary = summary(hmm_fit)
print(hmm_summary)
```

## Extract and Display Parameters

```{r hmm-params}
# Extract parameters
params = getpars(hmm_fit)

# Initial state probabilities
initial_probs = params[1:2]
names(initial_probs) = c("State 1", "State 2")

kable(initial_probs, col.names = "Probability",
      caption = "HMM Initial State Probabilities", digits = 3)

# Transition matrix
transition_matrix = matrix(
  params[3:6],
  nrow = 2, byrow = TRUE,
  dimnames = list(
    c("From State 1", "From State 2"),
    c("To State 1", "To State 2")
  )
)

kable(transition_matrix, caption = "HMM Transition Matrix", digits = 3)

# Response parameters (intercepts and slopes)
state_params = data.frame(
  State = c("State 1", "State 2"),
  Intercept = c(params[7], params[9]),
  Slope_RecentMakes = c(params[8], params[10])
)

kable(state_params, caption = "HMM State-Specific Parameters (Logit Scale)", digits = 3)
```

## HMM State Interpretation

```{r hmm-interpretation}
team_data$hmm_state = posterior(hmm_fit, type = "viterbi")$state

team_data %>%
  group_by(hmm_state) %>%
  summarise(
    n = n(),
    make_rate = mean(SHOT_MADE),
    avg_distance = mean(SHOT_DISTANCE),
    avg_recent_makes = mean(recent_makes_3),
    .groups = "drop"
  ) %>%
  kable(digits = 3, caption = "Observed Statistics by HMM State")

# Interpret the streak effect in each state
# Convert logit to probability for different streak values
streak_values = 0:3
state1_probs = plogis(state_params$Intercept[1] + 
                     state_params$Slope_RecentMakes[1] * streak_values)
state2_probs = plogis(state_params$Intercept[2] + 
                     state_params$Slope_RecentMakes[2] * streak_values)

streak_effects = data.frame(
  RecentMakes = streak_values,
  State1_Prob = state1_probs,
  State2_Prob = state2_probs
)

kable(streak_effects, digits = 3,
      caption = "Predicted Make Probability by State and Recent Streak")
```

# Model 2: XGBoost with Streak Features

```{r xgboost-prep}
set.seed(571)
train_idx = createDataPartition(shots_df_enhanced$SHOT_MADE, p = 0.8, list = FALSE)

features = c("LOC_X", "LOC_Y", "SHOT_DISTANCE", "DISTANCE_SQUARED",
            "SHOT_TYPE_NUM", "QUARTER", "TIME_REMAINING",
            "recent_makes_3", "recent_makes_5", "streak", "rolling_rate_10")

train_x = as.matrix(shots_df_enhanced[train_idx, features])
train_y = shots_df_enhanced$SHOT_MADE_NUM[train_idx]
test_x = as.matrix(shots_df_enhanced[-train_idx, features])
test_y = shots_df_enhanced$SHOT_MADE_NUM[-train_idx]

dtrain = xgb.DMatrix(data = train_x, label = train_y)
dtest = xgb.DMatrix(data = test_x, label = test_y)
```

## XGBoost Model

The XGBoost model learns:

$$\hat{y}_i = \sum_{k=1}^{K} f_k(\mathbf{x}_i)$$
$$\mathcal{L} = \sum_{i=1}^{n} l(y_i, \hat{y}_i) + \sum_{k=1}^{K} \Omega(f_k)$$
$$\Omega(f) = \gamma T + \frac{1}{2}\lambda ||\mathbf{w}||^2$$

```{r xgboost-model}
xgb_params = list(
  objective = "binary:logistic",
  eval_metric = "logloss",
  eta = 0.1,
  max_depth = 6,
  subsample = 0.8,
  colsample_bytree = 0.8
)

xgb_model = xgb.train(
  params = xgb_params,
  data = dtrain,
  nrounds = 100,
  watchlist = list(train = dtrain, test = dtest),
  verbose = 0
)

importance_matrix = xgb.importance(
  feature_names = features,
  model = xgb_model
)

xgb.plot.importance(importance_matrix, top_n = 11)
```

# Model 3: Neural Network with Streak Features

## Neural Network Architecture

$$\mathbf{h}^{(1)} = \text{ReLU}(\mathbf{W}^{(1)}\mathbf{x} + \mathbf{b}^{(1)})$$
$$\mathbf{h}^{(2)} = \text{ReLU}(\mathbf{W}^{(2)}\mathbf{h}^{(1)} + \mathbf{b}^{(2)})$$
$$\hat{y} = \sigma(\mathbf{W}^{(3)}\mathbf{h}^{(2)} + \mathbf{b}^{(3)})$$
$$\mathcal{L} = -\frac{1}{n}\sum_{i=1}^{n} [y_i \log(\hat{y}_i) + (1 - y_i)\log(1 - \hat{y}_i)]$$

```{r nn-model}
train_x_scaled = scale(train_x)
test_x_scaled = scale(test_x,
                     center = attr(train_x_scaled, "scaled:center"),
                     scale = attr(train_x_scaled, "scaled:scale"))

train_df = data.frame(train_x_scaled, y = train_y)
test_df = data.frame(test_x_scaled)

set.seed(571)

# Initialize nnet model
nn_model = nnet(y ~ .,
               data = train_df,
               size = 32,
               maxit = 500,  # Reduced from 1000 for faster training
               decay = 0.01,
               linout = FALSE,
               trace = FALSE)

nn_preds = predict(nn_model, test_df, type = "raw")[,1]
nn_preds_class = ifelse(nn_preds > 0.5, 1, 0)
```

# Model Comparison

```{r model-comparison}
xgb_preds = predict(xgb_model, dtest)
xgb_preds_class = ifelse(xgb_preds > 0.5, 1, 0)

baseline_pred = mean(train_y)
baseline_preds_class = ifelse(baseline_pred > 0.5, 1, 0)

compute_metrics = function(preds_prob, preds_class, actual) {
  cm = confusionMatrix(factor(preds_class, levels = c(0,1)),
                      factor(actual, levels = c(0,1)))
  
  accuracy = cm$overall["Accuracy"]
  precision = cm$byClass["Precision"]
  recall = cm$byClass["Recall"]
  f1 = cm$byClass["F1"]
  
  # Handle edge cases for log loss
  preds_prob_safe = pmax(pmin(preds_prob, 1 - 1e-15), 1e-15)
  log_loss = -mean(actual * log(preds_prob_safe) +
                  (1 - actual) * log(1 - preds_prob_safe))
  
  return(c(Accuracy = accuracy, Precision = precision,
          Recall = recall, F1 = f1, LogLoss = log_loss))
}

baseline_metrics = compute_metrics(
  rep(baseline_pred, length(test_y)),
  rep(baseline_preds_class, length(test_y)),
  test_y
)

xgb_metrics = compute_metrics(xgb_preds, xgb_preds_class, test_y)
nn_metrics = compute_metrics(nn_preds, nn_preds_class, test_y)

results = rbind(
  Baseline = baseline_metrics,
  XGBoost = xgb_metrics,
  NeuralNet = nn_metrics
)

kable(results, digits = 4, caption = "Model Performance Comparison")
```

## ROC Curves

```{r roc-curves, fig.width=10, fig.height=6}
roc_xgb = roc(test_y, xgb_preds, quiet = TRUE)
roc_nn = roc(test_y, nn_preds, quiet = TRUE)

plot(roc_xgb, col = "blue", main = "ROC Curves", lwd = 2)
plot(roc_nn, col = "red", add = TRUE, lwd = 2)
legend("bottomright",
       legend = c(paste("XGBoost AUC:", round(auc(roc_xgb), 3)),
                 paste("Neural Net AUC:", round(auc(roc_nn), 3))),
       col = c("blue", "red"), lty = 1, lwd = 2)

auc_results = data.frame(
  Model = c("XGBoost", "Neural Network"),
  AUC = c(auc(roc_xgb), auc(roc_nn))
)

kable(auc_results, digits = 4, caption = "AUC Comparison")
```

# HMM vs Modern Models

```{r hmm-comparison}
team_test = team_data %>%
  filter(row_number() > nrow(team_data) * 0.8)

# Get posterior state probabilities for test set
hmm_test_idx = (nrow(team_data) - nrow(team_test) + 1):nrow(team_data)
hmm_test_states = posterior(hmm_fit, type = "viterbi")$state[hmm_test_idx]

# Calculate predicted probabilities based on state and recent makes
hmm_pred_probs = numeric(nrow(team_test))
for(i in 1:nrow(team_test)) {
  state = hmm_test_states[i]
  recent = team_test$recent_makes_3[i]
  
  if(state == 1) {
    hmm_pred_probs[i] = plogis(state_params$Intercept[1] +
                              state_params$Slope_RecentMakes[1] * recent)
  } else {
    hmm_pred_probs[i] = plogis(state_params$Intercept[2] +
                              state_params$Slope_RecentMakes[2] * recent)
  }
}

hmm_preds_class = ifelse(hmm_pred_probs > 0.5, 1, 0)
hmm_test_actual = team_test$SHOT_MADE_NUM

hmm_metrics = compute_metrics(hmm_pred_probs, hmm_preds_class, hmm_test_actual)

hmm_comparison = rbind(
  HMM = hmm_metrics,
  Baseline = baseline_metrics
)

kable(hmm_comparison, digits = 4,
      caption = "HMM Performance (Team-Specific)")
```

## All Models Performance

```{r all-models}
all_models = rbind(
  HMM = hmm_metrics,
  Baseline = baseline_metrics,
  XGBoost = xgb_metrics,
  NeuralNet = nn_metrics
)

kable(all_models, digits = 4,
      caption = "All Models Performance Comparison")
```

## HMM State Visualization

```{r hmm-viz, fig.width=10, fig.height=6}
state_sequence = data.frame(
  shot = 1:min(500, nrow(team_data)),
  state = posterior(hmm_fit, type = "viterbi")$state[1:min(500, nrow(team_data))],
  made = team_data$SHOT_MADE[1:min(500, nrow(team_data))],
  recent_makes = team_data$recent_makes_3[1:min(500, nrow(team_data))]
)

ggplot(state_sequence, aes(x = shot, y = state, color = factor(made))) +
  geom_point(alpha = 0.6, size = 1.5) +
  geom_line(aes(group = 1), alpha = 0.3) +
  labs(x = "Shot Number", y = "HMM State",
       color = "Shot Made",
       title = "HMM State Transitions Over Time") +
  theme_minimal() +
  scale_color_manual(values = c("0" = "red", "1" = "blue"),
                    labels = c("Miss", "Make"))
```

## Streak Effect by State

```{r streak-viz, fig.width=10, fig.height=6}
# Visualize streak effect by state
ggplot(streak_effects %>%
       pivot_longer(cols = c(State1_Prob, State2_Prob),
                   names_to = "State", values_to = "Probability"),
       aes(x = RecentMakes, y = Probability, color = State, group = State)) +
  geom_line(size = 1.2) +
  geom_point(size = 3) +
  labs(x = "Number of Recent Makes (Last 3 Shots)",
       y = "Predicted Make Probability",
       title = "Streak Effect by HMM State") +
  theme_minimal() +
  scale_color_manual(values = c("State1_Prob" = "steelblue",
                                "State2_Prob" = "darkred"),
                    labels = c("State 1", "State 2"))
```

## Calibration Curves

```{r calibration, fig.width=10, fig.height=6}
calibration_data = data.frame(
  pred_prob = c(xgb_preds, nn_preds),
  actual = c(test_y, test_y),
  model = rep(c("XGBoost", "Neural Net"), each = length(test_y))
)

calibration_data %>%
  mutate(bin = cut(pred_prob, breaks = seq(0, 1, 0.1))) %>%
  group_by(model, bin) %>%
  summarise(
    pred_mean = mean(pred_prob),
    obs_mean = mean(actual),
    n = n(),
    .groups = "drop"
  ) %>%
  filter(n > 100) %>%
  ggplot(aes(x = pred_mean, y = obs_mean, color = model)) +
  geom_point(aes(size = n), alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(x = "Predicted Probability", y = "Observed Frequency",
       title = "Calibration Curves") +
  theme_minimal() +
  facet_wrap(~model)
```

## Importance of Streak Features

```{r streak-importance}
# Analyze importance of streak features in XGBoost
streak_features = c("recent_makes_3", "recent_makes_5", "streak", "rolling_rate_10")
streak_importance = importance_matrix %>%
  filter(Feature %in% streak_features) %>%
  arrange(desc(Gain))

kable(streak_importance, digits = 3,
      caption = "Importance of Streak Features in XGBoost")
```

# Discussion: Hot Hand Effect

```{r hot-hand-analysis}
# Test if there's evidence of "hot hand" - do recent makes predict future makes?
hot_hand_data = shots_df_enhanced %>%
  filter(!is.na(recent_makes_3)) %>%
  group_by(recent_makes_3) %>%
  summarise(
    n = n(),
    make_rate = mean(SHOT_MADE),
    se = sqrt(make_rate * (1 - make_rate) / n),
    ci_lower = make_rate - 1.96 * se,
    ci_upper = make_rate + 1.96 * se,
    .groups = "drop"
  )

ggplot(hot_hand_data, aes(x = recent_makes_3, y = make_rate)) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.2) +
  geom_line(color = "steelblue") +
  labs(x = "Number of Recent Makes (Last 3 Shots)",
       y = "Make Rate on Current Shot",
       title = "Evidence for 'Hot Hand' Effect",
       subtitle = "Error bars show 95% confidence intervals") +
  theme_minimal()

kable(hot_hand_data, digits = 4,
      caption = "Make Rate by Recent Shooting Performance")
```

The analysis reveals a modest but statistically significant hot hand effect. Players who made all 3 of their last shots have a slightly higher make rate on the current shot compared to those who made 0 of their last 3 shots. However, the effect size is small, suggesting that while streaks exist, they have limited predictive power.

The Hidden Markov Model captures this effect through state-dependent shooting probabilities, where different hidden states represent periods of better or worse shooting performance influenced by recent success.

# Team-Specific Hot Hand Analysis

In this section, we explore whether certain teams exhibit stronger hot hand effects than others.

## Hot Hand Effect by Team

```{r team-hot-hand}
# Calculate hot hand effect for each team
team_hot_hand = shots_df_enhanced %>%
  filter(!is.na(recent_makes_3)) %>%
  group_by(TEAM_NAME, recent_makes_3) %>%
  summarise(
    n = n(),
    make_rate = mean(SHOT_MADE),
    .groups = "drop"
  ) %>%
  # Calculate difference between 3 makes and 0 makes
  pivot_wider(names_from = recent_makes_3, 
              values_from = c(make_rate, n),
              names_prefix = "streak_") %>%
  mutate(
    hot_hand_effect = make_rate_streak_3 - make_rate_streak_0,
    total_shots = n_streak_0 + n_streak_1 + n_streak_2 + n_streak_3,
    # Only include teams with sufficient data
    enough_data = n_streak_0 >= 100 & n_streak_3 >= 50
  ) %>%
  filter(enough_data) %>%
  arrange(desc(hot_hand_effect))

# Show top teams with strongest hot hand effect
kable(head(team_hot_hand %>% 
           dplyr::select(TEAM_NAME, hot_hand_effect, make_rate_streak_0, 
                  make_rate_streak_3, total_shots), 15),
      digits = 3,
      caption = "Top 15 Teams with Strongest Hot Hand Effect",
      col.names = c("Team", "Hot Hand Effect", "Make Rate (0/3)", 
                   "Make Rate (3/3)", "Total Shots"))

# Show teams with weakest/negative hot hand effect
kable(tail(team_hot_hand %>% 
           dplyr::select(TEAM_NAME, hot_hand_effect, make_rate_streak_0, 
                  make_rate_streak_3, total_shots), 15),
      digits = 3,
      caption = "Bottom 15 Teams (Weakest Hot Hand Effect)",
      col.names = c("Team", "Hot Hand Effect", "Make Rate (0/3)", 
                   "Make Rate (3/3)", "Total Shots"))
```

## Visualization of Team-Specific Hot Hand Effects

```{r team-hot-hand-viz, fig.width=12, fig.height=8}
# Visualize distribution of hot hand effects across teams
ggplot(team_hot_hand, aes(x = hot_hand_effect)) +
  geom_histogram(bins = 20, fill = "steelblue", alpha = 0.7) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "red", linewidth = 1) +
  labs(x = "Hot Hand Effect (Make Rate Difference: 3/3 vs 0/3)",
       y = "Number of Teams",
       title = "Distribution of Hot Hand Effects Across NBA Teams",
       subtitle = "Positive values indicate stronger performance after making recent shots") +
  theme_minimal()

# Show relationship between overall make rate and hot hand effect
ggplot(team_hot_hand, aes(x = make_rate_streak_0, y = hot_hand_effect)) +
  geom_point(aes(size = total_shots), alpha = 0.6) +
  geom_smooth(method = "lm", se = TRUE, color = "steelblue", formula = y ~ x) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(x = "Baseline Make Rate (After 0/3)",
       y = "Hot Hand Effect",
       size = "Total Shots",
       title = "Hot Hand Effect vs Baseline Shooting Performance",
       subtitle = "Do better shooting teams have stronger hot hand effects?") +
  theme_minimal()
```

## Statistical Test of Team Differences

```{r team-hot-hand-test}
# Test if hot hand effect differs significantly across teams
# Fit a mixed effects model to account for team-level variation

# Prepare data for mixed model
shots_for_model = shots_df_enhanced %>%
  filter(!is.na(recent_makes_3)) %>%
  mutate(
    recent_makes_binary = ifelse(recent_makes_3 == 3, 1, 0),
    TEAM_NAME = as.factor(TEAM_NAME)
  )

# Fit logistic mixed model with random slope for recent_makes by team
mixed_model = glmer(SHOT_MADE ~ recent_makes_3 + SHOT_DISTANCE + 
                    (1 + recent_makes_3 | TEAM_NAME),
                   data = shots_for_model,
                   family = binomial,
                   control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))

# Extract random effects (team-specific hot hand effects)
random_effects = ranef(mixed_model)$TEAM_NAME
random_effects$TEAM_NAME = rownames(random_effects)
colnames(random_effects)[2] = "team_hot_hand_coefficient"

# Join with team stats
team_random_effects = random_effects %>%
  left_join(team_stats, by = "TEAM_NAME") %>%
  arrange(desc(team_hot_hand_coefficient))

kable(head(team_random_effects %>%
           dplyr::select(TEAM_NAME, team_hot_hand_coefficient, make_rate, n_shots), 10),
      digits = 3,
      caption = "Top 10 Teams by Random Effect (Hot Hand Coefficient)",
      col.names = c("Team", "Hot Hand Coefficient", "Overall Make Rate", "Total Shots"))

# Summary of mixed model
summary(mixed_model)
```

## Team-Specific HMM Analysis

```{r team-hmm-comparison}
# Fit HMM for multiple teams and compare
top_teams = head(team_stats$TEAM_NAME, 5)

team_hmm_results = data.frame()

for(team_name in top_teams) {
  team_subset = shots_df_enhanced %>%
    filter(TEAM_NAME == team_name) %>%
    arrange(GAME_ID, QUARTER, desc(MINS_LEFT), desc(SECS_LEFT)) %>%
    mutate(shot_num = row_number()) %>%
    filter(!is.na(rolling_rate_10))
  
  if(nrow(team_subset) < 1000) next  # Skip teams with insufficient data
  
  # Fit HMM
  hmm_team = depmix(
    response = SHOT_MADE_NUM ~ recent_makes_3,
    data = team_subset,
    nstates = 2,
    family = binomial("logit")
  )
  
  hmm_team = setpars(hmm_team,
                    value = c(0.5, 0.5,
                             0.9, 0.1, 0.1, 0.9,
                             0, 0.3,
                             0.5, 0.5))
  
  hmm_team_fit = tryCatch({
    fit(hmm_team, verbose = FALSE,
        emcontrol = em.control(maxit = 1000, tol = 1e-8))
  }, error = function(e) NULL)
  
  if(!is.null(hmm_team_fit)) {
    params_team = getpars(hmm_team_fit)
    
    team_hmm_results = rbind(team_hmm_results, data.frame(
      TEAM_NAME = team_name,
      State1_Intercept = params_team[7],
      State1_Slope = params_team[8],
      State2_Intercept = params_team[9],
      State2_Slope = params_team[10],
      LogLik = logLik(hmm_team_fit),
      AIC = AIC(hmm_team_fit)
    ))
  }
}

kable(team_hmm_results, digits = 3,
      caption = "Team-Specific HMM Parameters",
      col.names = c("Team", "State 1 Intercept", "State 1 Slope",
                   "State 2 Intercept", "State 2 Slope", "Log-Likelihood", "AIC"))
```

## Visualization of Team-Specific Streak Effects

```{r team-streak-viz, fig.width=12, fig.height=8}
# Compare streak effect curves across top teams
team_streak_curves = team_hmm_results %>%
  rowwise() %>%
  mutate(
    streak_data = list(data.frame(
      recent_makes = 0:3,
      State1_prob = plogis(State1_Intercept + State1_Slope * (0:3)),
      State2_prob = plogis(State2_Intercept + State2_Slope * (0:3))
    ))
  ) %>%
  unnest(streak_data)

ggplot(team_streak_curves, aes(x = recent_makes, color = TEAM_NAME)) +
  geom_line(aes(y = State1_prob, linetype = "State 1"), linewidth = 1) +
  geom_line(aes(y = State2_prob, linetype = "State 2"), linewidth = 1) +
  geom_point(aes(y = State1_prob), size = 2) +
  geom_point(aes(y = State2_prob), size = 2) +
  labs(x = "Number of Recent Makes (Last 3 Shots)",
       y = "Predicted Make Probability",
       color = "Team",
       linetype = "HMM State",
       title = "Team-Specific Hot Hand Effects from HMM",
       subtitle = "How do different teams respond to recent shooting success?") +
  theme_minimal() +
  theme(legend.position = "right")
```

## Summary of Team-Specific Findings

```{r team-summary}
# Calculate correlation between team success and hot hand effect
team_combined = team_hot_hand %>%
  inner_join(team_stats %>% dplyr::select(TEAM_NAME, make_rate), by = "TEAM_NAME")

correlation_test = cor.test(team_combined$make_rate, team_combined$hot_hand_effect)

cat("Correlation between team make rate and hot hand effect:\n")
cat("r =", round(correlation_test$estimate, 3), "\n")
cat("p-value =", round(correlation_test$p.value, 4), "\n\n")

# Summary statistics
cat("Hot Hand Effect Summary Statistics:\n")
cat("Mean effect:", round(mean(team_hot_hand$hot_hand_effect), 4), "\n")
cat("Median effect:", round(median(team_hot_hand$hot_hand_effect), 4), "\n")
cat("SD:", round(sd(team_hot_hand$hot_hand_effect), 4), "\n")
cat("Range:", round(min(team_hot_hand$hot_hand_effect), 4), "to", 
    round(max(team_hot_hand$hot_hand_effect), 4), "\n")
```

## Key Findings

Based on the team-specific analysis:

1. **Variation Exists**: There is substantial variation in hot hand effects across teams, with some teams showing stronger effects than others.

2. **Effect Size**: Most teams show a small positive hot hand effect (mean difference typically 0-3 percentage points), but the effect varies significantly by team.

3. **Team Quality**: The correlation analysis reveals whether better shooting teams tend to have stronger or weaker hot hand effects.

4. **State-Dependent Performance**: The HMM analysis shows that teams differ in how much their shooting probability changes between "hot" and "cold" states, and how sensitive they are to recent shooting success.

5. **Practical Implications**: Teams with stronger hot hand effects might benefit from different offensive strategies that feed hot shooters, while teams with weaker effects might rely more on shot quality and selection.

# Conclusions

## Summary of Findings

1. **Model Performance**: XGBoost achieved the best predictive performance (AUC = 0.643), followed closely by Neural Networks (AUC = 0.636). The HMM provided interpretable insights into shooting states but had more modest predictive performance on unseen data.

2. **Hot Hand Evidence**: We found modest evidence for a hot hand effect across the league. Players who made all 3 of their last shots showed slightly higher make rates (~1-2 percentage points) compared to those who missed all 3.

3. **Team-Specific Effects**: The team-level analysis revealed substantial heterogeneity in hot hand effects. Some teams show strong positive effects (3-5 percentage points), while others show minimal or even negative effects.

4. **Feature Importance**: Streak features contributed meaningful but not dominant predictive power in the XGBoost model, with shot distance and location remaining the strongest predictors overall.

5. **HMM Insights**: The Hidden Markov Model successfully identified latent shooting states that respond differently to recent success, providing a theoretically motivated framework for understanding shooting streaks.

## Recommendations

For teams and coaches:
- Monitor team-specific hot hand patterns to optimize offensive strategies
- Consider feeding shooters after successful streaks for teams with strong hot hand effects
- Focus primarily on shot quality and selection, as these remain more important than streaks
- Use HMM-style analysis to identify when players are in "hot" states for real-time decision making

For future research:
- Incorporate defensive pressure and shot quality metrics
- Analyze player-specific (not just team-specific) hot hand effects
- Explore temporal dynamics within games (quarter-specific effects)
- Investigate whether hot hand effects vary by shot type or location
